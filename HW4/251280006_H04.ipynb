{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twKpLeRhDeyQ"
      },
      "source": [
        "# Homework 4\n",
        "\n",
        "## Instructions\n",
        "Once you are finished, complete the following steps.\n",
        "\n",
        "1.  Restart your kernel and rerun everything.\n",
        "\n",
        "2.  Fix any errors which result from this.\n",
        "\n",
        "3.  Repeat the above until your notebook runs without errors.\n",
        "\n",
        "4.  Submit your completed notebook (.ipynb) to OWL by the deadline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waD8EZwFMt1U"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this homework, you will use a Heart Disease dataset to predict if a patient has heart disease or not. The features in the dataset are described below.\n",
        "\n",
        "*   **sex**:\tSex (1 = male; 0 = female)\n",
        "*   **cp**:\tChest pain type (1: typical angina; 2: atypical angina; 3: non-anginal pain; 4: asymptomatic)\n",
        "*   **trestbps**:\tResting blood pressure (in mm Hg on admission to the hospital)\n",
        "*   **chol**:\tSerum cholesterol in mg/dl\n",
        "*   **fbs**:\tFasting blood sugar > 120 mg/dl (1 = true; 0 = false)\n",
        "*   **restecg**:\tResting electrocardiographic results (0: normal; 1: having ST-T wave abnormality; 2: showing probable or definite left ventricular hypertrophy)\n",
        "*   **thalach**:\tMaximum heart rate achieved\n",
        "*   **exang**:\tExercise induced angina (1 = yes; 0 = no)\n",
        "*   **oldpeak**:\tST depression induced by exercise relative to rest\n",
        "*   **Class**: 1 if heart disease, 0 if no heart disease\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 1323,
          "status": "ok",
          "timestamp": 1769751002593,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "zJdm6Uxlq-kc"
      },
      "outputs": [],
      "source": [
        "# Package import\n",
        "import numpy as np\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.model_selection import train_test_split, cross_validate, RepeatedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, classification_report, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Data management imports\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "\n",
        "# Plotting imports\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2949,
          "status": "ok",
          "timestamp": 1769751005539,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "nKQxNU4X6i3I",
        "outputId": "acef6ae2-1eca-4d17-e83d-50a9ced02a5d"
      },
      "outputs": [],
      "source": [
        "# Uncomment the line below if you are using Google colab\n",
        "!gdown https://drive.google.com/uc?id=1fpNHlDypoSHvbH1EqFzkH_SGk7jVj9Vb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTKdVYZLGm-b"
      },
      "source": [
        "## Part 1\n",
        "\n",
        "1. Read the CSV file using **Polars** and store it using `null_values=['NA']`. Show **summary statistics** for the dataset. What is the **baseline accuracy** for a model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 16,
          "status": "ok",
          "timestamp": 1769751005555,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "Wj-Yl2t5JW0Y"
      },
      "outputs": [],
      "source": [
        "df_pl = pl.read_csv('Heart Disease Data.csv', null_values=['NA'])\n",
        "print(df_pl.describe())\n",
        "df = df_pl.to_pandas()\n",
        "baseline_accuracy = df['Class'].value_counts(normalize=True).max()\n",
        "print(f\"baseline accuracy: {baseline_accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6oA1stMv5Fj"
      },
      "source": [
        "**Written answer**: The baseline accuracy for the model is `XX.XX%` (fill in from cell above)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tw6pJdOcY_k"
      },
      "source": [
        "2. Assume that we are only interested in studying people aged **70 or less**. Remove anyone with ages larger than that. (Note that this will slightly change your baseline accuracy.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1769751005558,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "CwASQWPl87ye"
      },
      "outputs": [],
      "source": [
        "df = df[df['age'] <= 70]\n",
        "baseline_accuracy = df['Class'].value_counts(normalize=True).max()\n",
        "print(f\"shape: {df.shape}, baseline: {baseline_accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rSrLV3hnrek"
      },
      "source": [
        "3. Replace the missing values in the dataset using the **median** of the corresponding predictor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 33,
          "status": "ok",
          "timestamp": 1769751005602,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "htFdyZepn1uB"
      },
      "outputs": [],
      "source": [
        "for col in df.columns:\n",
        "    if df[col].isnull().any():\n",
        "        df[col] = df[col].fillna(df[col].median())\n",
        "print(df.isnull().sum().sum(), \"nulls remaining\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MqkK7Ve2JO_"
      },
      "source": [
        "Note: It was an **error** to have you fill in the missing values with the median based on the **entire dataset** rather than just the training set created in the next question. This leads to **data leakage** (although it is relatively minor). We did it in this coursework for simplicity only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR9-bjxqcZ_V"
      },
      "source": [
        "## Part 2\n",
        "\n",
        "4. Create a training and testing dataset. Reserve **30%** of the data for testing and stratify the split based on the outcome. Use a random state equal to your **Student ID**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1769751005604,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "uKXVS9DWcaPy"
      },
      "outputs": [],
      "source": [
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=251280006, stratify=y\n",
        ")\n",
        "\n",
        "print(X_train.shape[0], \"train,\", X_test.shape[0], \"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD6jBNP7wd_d"
      },
      "source": [
        "5. Using **all** potential features, train a **logistic regression model** to predict if a patient has the condition. Remember to **standardise** the features. Use the following arguments.\n",
        "\n",
        "*   `solver = 'lbfgs'`\n",
        "*   `penalty = None`\n",
        "*   `max_iter = 10000`\n",
        "*   `verbose = 1`\n",
        "*   `random_state = 0`\n",
        "*   `n_jobs = -1`\n",
        "*   `class_weight = 'balanced'`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 103,
          "status": "ok",
          "timestamp": 1769751005708,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "SVgbr2N1wt97"
      },
      "outputs": [],
      "source": [
        "feature_cols = X_train.columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[('scaler', StandardScaler(), feature_cols)],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(\n",
        "        solver='lbfgs', penalty=None, max_iter=10000, verbose=1,\n",
        "        random_state=0, n_jobs=-1, class_weight='balanced'\n",
        "    ))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FNliCyvxT19"
      },
      "source": [
        "6. Compute the **accuracy** and **AUC** of your model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 24,
          "status": "ok",
          "timestamp": 1769751005720,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "Qo-ltgtixP8w"
      },
      "outputs": [],
      "source": [
        "y_pred = pipeline.predict(X_test)\n",
        "y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(f\"accuracy: {accuracy:.2%}, auc: {auc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rW83_ns5dRP"
      },
      "source": [
        "**Written answer:** Accuracy and AUC are in the cell above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFgizytIy143"
      },
      "source": [
        "## Part 3\n",
        "\n",
        "7. Without estimates of the uncertainty of the performance metrics, it can be hard to make definitive conclusions about the model performance. Compute **90% confidence intervals** for the accuracy and AUC using **bootstrapping** with **800** replicates. Interpret your results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 24,
          "status": "ok",
          "timestamp": 1769751005721,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "cr4Vaxsry2la"
      },
      "outputs": [],
      "source": [
        "n_bootstrap = 800\n",
        "rng = np.random.default_rng(0)\n",
        "\n",
        "boot_accuracy = []\n",
        "boot_auc = []\n",
        "n_test = len(y_test)\n",
        "\n",
        "for _ in range(n_bootstrap):\n",
        "    idx = rng.integers(0, n_test, size=n_test)\n",
        "    y_b = y_test.values[idx]\n",
        "    y_pred_b = pipeline.predict(X_test.iloc[idx])\n",
        "    y_proba_b = pipeline.predict_proba(X_test.iloc[idx])[:, 1]\n",
        "    boot_accuracy.append(accuracy_score(y_b, y_pred_b))\n",
        "    boot_auc.append(roc_auc_score(y_b, y_proba_b))\n",
        "\n",
        "boot_accuracy = np.array(boot_accuracy)\n",
        "boot_auc = np.array(boot_auc)\n",
        "\n",
        "acc_ci_low = np.percentile(boot_accuracy, 5)\n",
        "acc_ci_high = np.percentile(boot_accuracy, 95)\n",
        "auc_ci_low = np.percentile(boot_auc, 5)\n",
        "auc_ci_high = np.percentile(boot_auc, 95)\n",
        "\n",
        "print(f\"90% CI accuracy: [{acc_ci_low:.2%}, {acc_ci_high:.2%}]\")\n",
        "print(f\"90% CI auc: [{auc_ci_low:.4f}, {auc_ci_high:.4f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxiy5SdXztLC"
      },
      "source": [
        "**Written answer:** CIs above. Model is reasonable because intervals are above baseline and AUC > 0.5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1Q_m8y2J-Nv"
      },
      "source": [
        "8. Plot the distribution of the accuracy using **histogram**. Provide a title and axes labels for your plots. Add a **purple** vertical line representing the mean of accuracy. Repeat the same for the AUC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 24,
          "status": "ok",
          "timestamp": 1769751005723,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "H-jG2Z_sJ-rL"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(boot_accuracy, bins=30, edgecolor='black', alpha=0.7)\n",
        "plt.axvline(boot_accuracy.mean(), color='purple', linewidth=2, label='mean')\n",
        "plt.xlabel('accuracy')\n",
        "plt.ylabel('frequency')\n",
        "plt.title('distribution of bootstrap accuracy')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(boot_auc, bins=30, edgecolor='black', alpha=0.7)\n",
        "plt.axvline(boot_auc.mean(), color='purple', linewidth=2, label='mean')\n",
        "plt.xlabel('auc')\n",
        "plt.ylabel('frequency')\n",
        "plt.title('distribution of bootstrap auc')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1769751005725,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "nQHgBLMjKLC8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoP1pP6l5L4h"
      },
      "source": [
        "## Part 4\n",
        "\n",
        "9. Compute **90%** confidence intervals for the accuracy and AUC using **repeated cross-validation**. Use **10** splits and **100** repetitions with a random state of **0**. Compare your results to what you obtained using bootstrapping. Which method provides better confidence intervals in this case?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1769751005727,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "uSeWUQTZ5MDe"
      },
      "outputs": [],
      "source": [
        "rkf = RepeatedKFold(n_splits=10, n_repeats=100, random_state=0)\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    pipeline, X_train, y_train,\n",
        "    cv=rkf, scoring=['accuracy', 'roc_auc'],\n",
        "    return_estimator=True, n_jobs=-1\n",
        ")\n",
        "\n",
        "cv_accuracy = cv_results['test_accuracy']\n",
        "cv_auc = cv_results['test_roc_auc']\n",
        "\n",
        "acc_cv_low = np.percentile(cv_accuracy, 5)\n",
        "acc_cv_high = np.percentile(cv_accuracy, 95)\n",
        "auc_cv_low = np.percentile(cv_auc, 5)\n",
        "auc_cv_high = np.percentile(cv_auc, 95)\n",
        "\n",
        "print(f\"90% CI for accuracy (repeated cv): [{acc_cv_low:.2%}, {acc_cv_high:.2%}]\")\n",
        "print(f\"90% CI for auc (repeated cv): [{auc_cv_low:.4f}, {auc_cv_high:.4f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1769751005729,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "oCdmGJYM5fjm"
      },
      "outputs": [],
      "source": [
        "print(f\"bootstrap acc CI: [{acc_ci_low:.2%}, {acc_ci_high:.2%}]\"); print(f\"cv acc CI: [{acc_cv_low:.2%}, {acc_cv_high:.2%}]\")\n",
        "print(f\"bootstrap auc CI: [{auc_ci_low:.4f}, {auc_ci_high:.4f}]\"); print(f\"cv auc CI: [{auc_cv_low:.4f}, {auc_cv_high:.4f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z893LWUjNW_"
      },
      "source": [
        "**Written answer:** CIs above. Repeated CV gives better intervals (uses many splits; bootstrap uses one test set)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqvhSwBM8riL"
      },
      "source": [
        "10. Using your cross-validation results, compute a **95%** confidence interval for each feature in the model. Which features should you remove since they have their 95% confidence intervals **include zero**?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1769751005732,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "ULcmyhK48t9v"
      },
      "outputs": [],
      "source": [
        "estimators = cv_results['estimator']\n",
        "n_features = len(feature_cols)\n",
        "coefs = np.array([[e.named_steps['classifier'].coef_[0][j] for j in range(n_features)] for e in estimators])\n",
        "\n",
        "coef_ci_low = np.percentile(coefs, 2.5, axis=0)\n",
        "coef_ci_high = np.percentile(coefs, 97.5, axis=0)\n",
        "\n",
        "for i, name in enumerate(feature_cols):\n",
        "    inc = (coef_ci_low[i] <= 0 <= coef_ci_high[i])\n",
        "    print(f\"{name}: [{coef_ci_low[i]:.3f}, {coef_ci_high[i]:.3f}]  zero: {inc}\")\n",
        "features_to_remove = [feature_cols[i] for i in range(n_features) if coef_ci_low[i] <= 0 <= coef_ci_high[i]]\n",
        "print(\"remove:\", features_to_remove if features_to_remove else \"none (use sex)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDhYQMGNG_kt"
      },
      "source": [
        "**Written answer:** Remove features listed above (CI includes zero). If none, remove sex."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZvnP0Wc81Og"
      },
      "source": [
        "11. Fit your logistic regression model like before but remove the features you indentified in Q10. If you did not identify any features in Q10, remove **sex** instead. Plot the **ROC curve** of the model over the test set and **annotate** it with the AUC of the model. Provide a title and axes labels for your plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1769751005734,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "h506WTyw8xIq"
      },
      "outputs": [],
      "source": [
        "drop_cols = features_to_remove if features_to_remove else ['sex']\n",
        "cols_red = [c for c in feature_cols if c not in drop_cols]\n",
        "pipe_red = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('classifier', LogisticRegression(solver='lbfgs', penalty=None, max_iter=10000, verbose=0, random_state=0, n_jobs=-1, class_weight='balanced'))\n",
        "])\n",
        "pipe_red.fit(X_train[cols_red], y_train)\n",
        "y_proba_red = pipe_red.predict_proba(X_test[cols_red])[:, 1]\n",
        "auc_red = roc_auc_score(y_test, y_proba_red)\n",
        "fpr_red, tpr_red, _ = roc_curve(y_test, y_proba_red)\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(fpr_red, tpr_red, 'b-')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.text(0.6, 0.2, f'auc = {auc_red:.3f}')\n",
        "plt.xlabel('false positive rate')\n",
        "plt.ylabel('true positive rate')\n",
        "plt.title('roc curve (reduced model)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1769751005737
        },
        "id": "8w5t968Fwnus"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FHVaoRi80ZK"
      },
      "source": [
        "12. Iterate through your cross-validation created in Q9 and calculate the uncertainty for the prediction of the **second** testing patient. Plot a **histogram** of the different predictions. Provide a title and axes labels for your plot. Add a **purple** vertical line representing the mean of the predictions.\n",
        "\n",
        "Hint: If you need to stack a list of arrays, you can use [np.hstack(list)](https://numpy.org/doc/stable/reference/generated/numpy.hstack.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1769751005739,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "vbyP6_ssNOh4"
      },
      "outputs": [],
      "source": [
        "preds_second = []\n",
        "for (_, test_idx), est in zip(rkf.split(X_train, y_train), cv_results['estimator']):\n",
        "    x_second = X_train.iloc[test_idx[1]:test_idx[1]+1]\n",
        "    preds_second.append(est.predict_proba(x_second)[0, 1])\n",
        "preds_second = np.array(preds_second)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.hist(preds_second, bins=25, edgecolor='black', alpha=0.7)\n",
        "plt.axvline(preds_second.mean(), color='purple', linewidth=2, label='mean')\n",
        "plt.xlabel('predicted probability')\n",
        "plt.ylabel('frequency')\n",
        "plt.title('predictions for second test patient (each fold)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 10,
          "status": "ok",
          "timestamp": 1769751005748,
          "user": {
            "displayName": "Hikariヒカリ",
            "userId": "03012894335521349384"
          },
          "user_tz": 300
        },
        "id": "uvaPzSUhO98k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Nf9RtjLVLgh"
      },
      "source": [
        "## End of Homework 4"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [
        {
          "file_id": "1r6zBj_Yo7hGra8A8swFbHVY4UvFb5vjQ",
          "timestamp": 1738079020338
        },
        {
          "file_id": "1cuCZODCO2UhPt2wQyzt3tcO6y3iRO0QD",
          "timestamp": 1736827747029
        },
        {
          "file_id": "11M2GDQXAjsFjjVRuWaGQlFLrunfq_gmO",
          "timestamp": 1736730198357
        }
      ]
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
